{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Collaborative Filtering for Rating Prediction\n",
        "\n",
        "## Motivation\n",
        "\n",
        "The original NCF (He et al., 2017) was designed for **implicit feedback** (binary interactions: clicked/not clicked). It uses:\n",
        "- **Binary Cross-Entropy loss** (BCEWithLogitsLoss)\n",
        "- **Negative sampling** to create (user, item, 0/1) pairs\n",
        "- Output passed through **sigmoid** → probability of interaction\n",
        "\n",
        "However, for **explicit feedback** (ratings 1-5), we need to:\n",
        "1. Replace BCE loss with **MSE loss** (regression task)\n",
        "2. Remove negative sampling (use actual ratings as targets)\n",
        "3. Scale output to rating range [1, 5] or keep unbounded\n",
        "\n",
        "## Key Modifications\n",
        "\n",
        "| Component | Original NCF (Implicit) | Rating NCF (Explicit) |\n",
        "|-----------|------------------------|----------------------|\n",
        "| Loss | BCEWithLogitsLoss | MSELoss |\n",
        "| Output | Logits → Sigmoid → [0,1] | Direct score → [1,5] |\n",
        "| Data | Binary labels (0/1) | Actual ratings (1-5) |\n",
        "| Sampling | Negative sampling | No negative sampling |\n",
        "| Evaluation | HR@K, NDCG@K | RMSE, MAE |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Add src to path\n",
        "current_dir = os.getcwd()\n",
        "path = current_dir\n",
        "while True:\n",
        "    if os.path.basename(path) == \"src\":\n",
        "        if path not in sys.path:\n",
        "            sys.path.insert(0, path)\n",
        "        break\n",
        "    parent = os.path.dirname(path)\n",
        "    if parent == path:\n",
        "        break\n",
        "    path = parent\n",
        "\n",
        "from helpers import download_ml1m_dataset\n",
        "\n",
        "# Reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paths\n",
        "DATA_DIR = os.path.join(os.path.dirname(os.getcwd()), '..', 'data')\n",
        "MODEL_PATH = os.path.join(os.path.dirname(os.getcwd()), '..', 'models')\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_PATH, exist_ok=True)\n",
        "\n",
        "# Hyperparameters\n",
        "LEARNING_RATE = 0.001\n",
        "DROPOUT_RATE = 0.2\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 50\n",
        "FACTOR_NUM = 32         # Embedding dimension\n",
        "NUM_LAYERS = 3          # MLP depth\n",
        "EARLY_STOPPING_PATIENCE = 10\n",
        "TEST_RATIO = 0.2        # 80/20 train/test split\n",
        "\n",
        "# Rating range for ML-1M\n",
        "RATING_MIN = 1.0\n",
        "RATING_MAX = 5.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Load and Prepare Data with Ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download dataset\n",
        "ratings_file = download_ml1m_dataset(DATA_DIR)\n",
        "\n",
        "# Load ratings with actual values\n",
        "ratings_df = pd.read_csv(\n",
        "    ratings_file,\n",
        "    sep='::',\n",
        "    engine='python',\n",
        "    names=['user_id', 'item_id', 'rating', 'timestamp'],\n",
        "    encoding='latin-1'\n",
        ")\n",
        "\n",
        "print(f\"Total ratings: {len(ratings_df):,}\")\n",
        "print(f\"Users: {ratings_df['user_id'].nunique():,}\")\n",
        "print(f\"Items: {ratings_df['item_id'].nunique():,}\")\n",
        "print(f\"Rating distribution:\\n{ratings_df['rating'].value_counts().sort_index()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Re-index users and items to start from 0\n",
        "user_ids = ratings_df['user_id'].unique()\n",
        "item_ids = ratings_df['item_id'].unique()\n",
        "\n",
        "user_to_idx = {uid: idx for idx, uid in enumerate(user_ids)}\n",
        "item_to_idx = {iid: idx for idx, iid in enumerate(item_ids)}\n",
        "\n",
        "ratings_df['user_idx'] = ratings_df['user_id'].map(user_to_idx)\n",
        "ratings_df['item_idx'] = ratings_df['item_id'].map(item_to_idx)\n",
        "\n",
        "num_users = len(user_ids)\n",
        "num_items = len(item_ids)\n",
        "\n",
        "print(f\"Indexed users: {num_users}, items: {num_items}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/Test split (random 80/20)\n",
        "train_df, test_df = train_test_split(\n",
        "    ratings_df,\n",
        "    test_size=TEST_RATIO,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Train samples: {len(train_df):,}\")\n",
        "print(f\"Test samples: {len(test_df):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: PyTorch Dataset for Rating Prediction\n",
        "\n",
        "**Key difference from original NCF**: No negative sampling. We use actual ratings as targets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RatingDataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for rating prediction (explicit feedback).\n",
        "    \n",
        "    Unlike NCFData which uses binary labels and negative sampling,\n",
        "    this dataset provides actual rating values as targets.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, df):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            df: DataFrame with columns ['user_idx', 'item_idx', 'rating']\n",
        "        \"\"\"\n",
        "        self.users = torch.LongTensor(df['user_idx'].values)\n",
        "        self.items = torch.LongTensor(df['item_idx'].values)\n",
        "        self.ratings = torch.FloatTensor(df['rating'].values)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.ratings)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.users[idx], self.items[idx], self.ratings[idx]\n",
        "\n",
        "\n",
        "# Create datasets and loaders\n",
        "train_dataset = RatingDataset(train_df)\n",
        "test_dataset = RatingDataset(test_df)\n",
        "\n",
        "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}, Test batches: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: NCF Model Modified for Rating Prediction\n",
        "\n",
        "**Modification**: Output layer maps to rating range [1, 5] using scaled sigmoid."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NCFRating(nn.Module):\n",
        "    \"\"\"\n",
        "    Neural Collaborative Filtering for Rating Prediction.\n",
        "    \n",
        "    Key differences from original NCF:\n",
        "    1. Output activation: Scaled sigmoid to map to [rating_min, rating_max]\n",
        "    2. Task: Regression (predict exact rating) instead of classification\n",
        "    \n",
        "    Architecture remains the same:\n",
        "    - GMF path: Element-wise product (linear interaction)\n",
        "    - MLP path: Deep neural network (non-linear interaction)\n",
        "    - NeuMF: Combination of both\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, num_users, num_items, factor_num, num_layers,\n",
        "                 dropout, model_name='NeuMF-end', rating_min=1.0, rating_max=5.0):\n",
        "        super(NCFRating, self).__init__()\n",
        "        \n",
        "        self.model_name = model_name\n",
        "        self.dropout = dropout\n",
        "        self.rating_min = rating_min\n",
        "        self.rating_max = rating_max\n",
        "        \n",
        "        # ================================================================\n",
        "        # GMF Embeddings (for linear interaction)\n",
        "        # ================================================================\n",
        "        if model_name != 'MLP':\n",
        "            self.embed_user_GMF = nn.Embedding(num_users, factor_num)\n",
        "            self.embed_item_GMF = nn.Embedding(num_items, factor_num)\n",
        "        \n",
        "        # ================================================================\n",
        "        # MLP Embeddings (for non-linear interaction)\n",
        "        # ================================================================\n",
        "        if model_name != 'GMF':\n",
        "            mlp_embed_dim = factor_num * (2 ** (num_layers - 1))\n",
        "            self.embed_user_MLP = nn.Embedding(num_users, mlp_embed_dim)\n",
        "            self.embed_item_MLP = nn.Embedding(num_items, mlp_embed_dim)\n",
        "        \n",
        "        # ================================================================\n",
        "        # MLP Layers\n",
        "        # ================================================================\n",
        "        if model_name != 'GMF':\n",
        "            layers = []\n",
        "            for i in range(num_layers):\n",
        "                input_size = factor_num * (2 ** (num_layers - i))\n",
        "                layers.append(nn.Dropout(p=dropout))\n",
        "                layers.append(nn.Linear(input_size, input_size // 2))\n",
        "                layers.append(nn.ReLU())\n",
        "            self.MLP_layers = nn.Sequential(*layers)\n",
        "        \n",
        "        # ================================================================\n",
        "        # Prediction Layer\n",
        "        # ================================================================\n",
        "        if model_name in ['MLP', 'GMF']:\n",
        "            predict_size = factor_num\n",
        "        else:\n",
        "            predict_size = factor_num * 2\n",
        "        \n",
        "        self.predict_layer = nn.Linear(predict_size, 1)\n",
        "        \n",
        "        # Initialize weights\n",
        "        self._init_weights()\n",
        "    \n",
        "    def _init_weights(self):\n",
        "        \"\"\"Xavier/Kaiming initialization for better convergence.\"\"\"\n",
        "        for name, param in self.named_parameters():\n",
        "            if 'embed' in name:\n",
        "                nn.init.normal_(param, std=0.01)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "            elif 'bias' in name:\n",
        "                nn.init.zeros_(param)\n",
        "    \n",
        "    def forward(self, user, item):\n",
        "        \"\"\"\n",
        "        Forward pass: predict rating for (user, item) pairs.\n",
        "        \n",
        "        Returns:\n",
        "            Predicted ratings in range [rating_min, rating_max]\n",
        "        \"\"\"\n",
        "        # GMF path\n",
        "        if self.model_name != 'MLP':\n",
        "            user_gmf = self.embed_user_GMF(user)\n",
        "            item_gmf = self.embed_item_GMF(item)\n",
        "            output_gmf = user_gmf * item_gmf  # Element-wise product\n",
        "        \n",
        "        # MLP path\n",
        "        if self.model_name != 'GMF':\n",
        "            user_mlp = self.embed_user_MLP(user)\n",
        "            item_mlp = self.embed_item_MLP(item)\n",
        "            interaction = torch.cat([user_mlp, item_mlp], dim=-1)\n",
        "            output_mlp = self.MLP_layers(interaction)\n",
        "        \n",
        "        # Combine paths\n",
        "        if self.model_name == 'GMF':\n",
        "            concat = output_gmf\n",
        "        elif self.model_name == 'MLP':\n",
        "            concat = output_mlp\n",
        "        else:\n",
        "            concat = torch.cat([output_gmf, output_mlp], dim=-1)\n",
        "        \n",
        "        # Predict raw score\n",
        "        logits = self.predict_layer(concat).view(-1)\n",
        "        \n",
        "        # Scale to rating range using sigmoid\n",
        "        # sigmoid output in [0, 1] → scale to [rating_min, rating_max]\n",
        "        rating_range = self.rating_max - self.rating_min\n",
        "        prediction = torch.sigmoid(logits) * rating_range + self.rating_min\n",
        "        \n",
        "        return prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Evaluation Metrics (RMSE, MAE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(model, data_loader, device):\n",
        "    \"\"\"\n",
        "    Evaluate model using RMSE and MAE.\n",
        "    \n",
        "    RMSE (Root Mean Squared Error): sqrt(mean((pred - actual)^2))\n",
        "    MAE (Mean Absolute Error): mean(|pred - actual|)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for user, item, rating in data_loader:\n",
        "            user, item = user.to(device), item.to(device)\n",
        "            pred = model(user, item)\n",
        "            predictions.extend(pred.cpu().numpy())\n",
        "            actuals.extend(rating.numpy())\n",
        "    \n",
        "    predictions = np.array(predictions)\n",
        "    actuals = np.array(actuals)\n",
        "    \n",
        "    rmse = np.sqrt(np.mean((predictions - actuals) ** 2))\n",
        "    mae = np.mean(np.abs(predictions - actuals))\n",
        "    \n",
        "    return rmse, mae"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create model\n",
        "model = NCFRating(\n",
        "    num_users=num_users,\n",
        "    num_items=num_items,\n",
        "    factor_num=FACTOR_NUM,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dropout=DROPOUT_RATE,\n",
        "    model_name='NeuMF-end',\n",
        "    rating_min=RATING_MIN,\n",
        "    rating_max=RATING_MAX\n",
        ").to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "# MSE Loss for regression (rating prediction)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Model: NCFRating (NeuMF-end)\")\n",
        "print(f\"Trainable parameters: {total_params:,}\")\n",
        "print(f\"Loss function: MSELoss (regression)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training\n",
        "best_rmse = float('inf')\n",
        "patience_counter = 0\n",
        "history = {'train_loss': [], 'test_rmse': [], 'test_mae': []}\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"Training NCF for Rating Prediction\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    start_time = time.time()\n",
        "    \n",
        "    for user, item, rating in train_loader:\n",
        "        user, item, rating = user.to(device), item.to(device), rating.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        prediction = model(user, item)\n",
        "        loss = criterion(prediction, rating)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item() * len(rating)\n",
        "    \n",
        "    avg_loss = total_loss / len(train_dataset)\n",
        "    \n",
        "    # Evaluate\n",
        "    test_rmse, test_mae = evaluate(model, test_loader, device)\n",
        "    \n",
        "    elapsed = time.time() - start_time\n",
        "    \n",
        "    # Store history\n",
        "    history['train_loss'].append(avg_loss)\n",
        "    history['test_rmse'].append(test_rmse)\n",
        "    history['test_mae'].append(test_mae)\n",
        "    \n",
        "    # Early stopping check\n",
        "    if test_rmse < best_rmse:\n",
        "        best_rmse = test_rmse\n",
        "        patience_counter = 0\n",
        "        # Save best model\n",
        "        torch.save(model.state_dict(), os.path.join(MODEL_PATH, 'NCF-Rating.pth'))\n",
        "        marker = \" ✓ Best\"\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        marker = \"\"\n",
        "    \n",
        "    print(f\"Epoch {epoch+1:02d}/{EPOCHS} | Loss: {avg_loss:.4f} | \"\n",
        "          f\"RMSE: {test_rmse:.4f} | MAE: {test_mae:.4f} | \"\n",
        "          f\"Time: {elapsed:.1f}s{marker}\")\n",
        "    \n",
        "    if patience_counter >= EARLY_STOPPING_PATIENCE:\n",
        "        print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"Best Test RMSE: {best_rmse:.4f}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Visualize Training Progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Training loss\n",
        "axes[0].plot(history['train_loss'], 'b-', label='Train Loss')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('MSE Loss')\n",
        "axes[0].set_title('Training Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Test metrics\n",
        "axes[1].plot(history['test_rmse'], 'r-', label='RMSE')\n",
        "axes[1].plot(history['test_mae'], 'g-', label='MAE')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Error')\n",
        "axes[1].set_title('Test Metrics')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(MODEL_PATH, 'ncf_rating_training.png'), dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Example Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model\n",
        "model.load_state_dict(torch.load(os.path.join(MODEL_PATH, 'NCF-Rating.pth')))\n",
        "model.eval()\n",
        "\n",
        "# Sample predictions\n",
        "sample_df = test_df.sample(10, random_state=42)\n",
        "\n",
        "with torch.no_grad():\n",
        "    users = torch.LongTensor(sample_df['user_idx'].values).to(device)\n",
        "    items = torch.LongTensor(sample_df['item_idx'].values).to(device)\n",
        "    preds = model(users, items).cpu().numpy()\n",
        "\n",
        "print(\"Sample Predictions vs Actual Ratings\")\n",
        "print(\"=\"*50)\n",
        "for i, (_, row) in enumerate(sample_df.iterrows()):\n",
        "    print(f\"User {row['user_id']:4d} | Item {row['item_id']:4d} | \"\n",
        "          f\"Actual: {row['rating']:.0f} | Predicted: {preds[i]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### Key Changes from Original NCF\n",
        "\n",
        "1. **Loss Function**: `BCEWithLogitsLoss` → `MSELoss`\n",
        "2. **Output Activation**: Scaled sigmoid to [1, 5] range\n",
        "3. **Data Handling**: Direct ratings instead of binary labels\n",
        "4. **Evaluation Metrics**: RMSE/MAE instead of HR@K/NDCG@K\n",
        "5. **No Negative Sampling**: All training data has actual ratings\n",
        "\n",
        "### References\n",
        "\n",
        "- He, X., et al. (2017). Neural Collaborative Filtering. WWW'17.\n",
        "- Koren, Y., et al. (2009). Matrix Factorization Techniques for Recommender Systems. Computer."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
