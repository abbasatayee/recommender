{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hybrid AutoRec-NCF for Ranking (Implicit Feedback)\n",
        "\n",
        "## Motivation\n",
        "\n",
        "This notebook adapts the Hybrid AutoRec-NCF model for **implicit feedback** ranking tasks.\n",
        "\n",
        "### Key Features:\n",
        "\n",
        "1. **Data**: Binary interactions (ratings >= 4 as positive, 0 otherwise)\n",
        "2. **Loss**: BCEWithLogitsLoss for binary classification\n",
        "3. **Negative Sampling**: Sample negative items during training\n",
        "4. **Evaluation**: HR@K and NDCG@K metrics (same as NCF)\n",
        "\n",
        "### Approach:\n",
        "\n",
        "- Filter ratings >= 4 as positive interactions\n",
        "- Use negative sampling (NUM_NG negatives per positive)\n",
        "- Train with binary cross-entropy loss\n",
        "- Evaluate using HR@K and NDCG@K metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# Walk up the directory tree until we find 'src'\n",
        "path = current_dir\n",
        "src_path = None\n",
        "\n",
        "while True:\n",
        "    if os.path.basename(path) == \"src\":\n",
        "        src_path = path\n",
        "        break\n",
        "    parent = os.path.dirname(path)\n",
        "    if parent == path:  # reached filesystem root\n",
        "        break\n",
        "    path = parent\n",
        "\n",
        "# Add src to sys.path if found\n",
        "if src_path and src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)\n",
        "\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Local imports\n",
        "from helpers.data_downloader import download_ml1m_dataset\n",
        "from helpers.ranking_metrics import hit, ndcg\n",
        "from ncf.utils.ml_to_ncf import preprocess_ml1m_to_ncf_format\n",
        "from ncf.utils.load_all_data import load_all_data\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        latent_dim: int,\n",
        "        hidden_dims=(256, 128),\n",
        "        dropout_rate: float = 0.1,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_dim: dimensionality of input vector (e.g. user interaction vector)\n",
        "            latent_dim: size of bottleneck (MUST match NCF latent_dim)\n",
        "            hidden_dims: encoder hidden layer sizes\n",
        "            dropout_rate: dropout applied to hidden layers\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # =======================\n",
        "        # Encoder\n",
        "        # =======================\n",
        "        encoder_layers = []\n",
        "        prev_dim = input_dim\n",
        "\n",
        "        for h in hidden_dims:\n",
        "            encoder_layers.append(nn.Linear(prev_dim, h))\n",
        "            encoder_layers.append(nn.ReLU())\n",
        "            encoder_layers.append(nn.Dropout(dropout_rate))\n",
        "            prev_dim = h\n",
        "\n",
        "        # Bottleneck (NO activation)\n",
        "        encoder_layers.append(nn.Linear(prev_dim, latent_dim))\n",
        "        self.encoder = nn.Sequential(*encoder_layers)\n",
        "\n",
        "        # =======================\n",
        "        # Decoder\n",
        "        # =======================\n",
        "        decoder_layers = []\n",
        "        prev_dim = latent_dim\n",
        "\n",
        "        for h in reversed(hidden_dims):\n",
        "            decoder_layers.append(nn.Linear(prev_dim, h))\n",
        "            decoder_layers.append(nn.ReLU())\n",
        "            decoder_layers.append(nn.Dropout(dropout_rate))\n",
        "            prev_dim = h\n",
        "\n",
        "        decoder_layers.append(nn.Linear(prev_dim, input_dim))\n",
        "        decoder_layers.append(nn.Sigmoid())  # For binary reconstruction\n",
        "\n",
        "        self.decoder = nn.Sequential(*decoder_layers)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def encode(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encode(x)\n",
        "        recon = self.decode(z)\n",
        "        return recon, z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NCF(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        latent_dim,\n",
        "        mlp_layers=(128, 64),\n",
        "        dropout_rate=0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # =======================\n",
        "        # GMF (pure interaction)\n",
        "        # =======================\n",
        "        # No parameters here by design\n",
        "\n",
        "        # =======================\n",
        "        # MLP\n",
        "        # =======================\n",
        "        mlp_modules = []\n",
        "        input_dim = latent_dim * 2\n",
        "\n",
        "        for h in mlp_layers:\n",
        "            mlp_modules.append(nn.Linear(input_dim, h))\n",
        "            mlp_modules.append(nn.ReLU())\n",
        "            mlp_modules.append(nn.Dropout(dropout_rate))\n",
        "            input_dim = h\n",
        "\n",
        "        self.mlp = nn.Sequential(*mlp_modules)\n",
        "\n",
        "        # =======================\n",
        "        # Final prediction layer\n",
        "        # =======================\n",
        "        mlp_out_dim = mlp_layers[-1] if len(mlp_layers) > 0 else input_dim\n",
        "        self.output = nn.Linear(latent_dim + mlp_out_dim, 1)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, user_z, item_z):\n",
        "        # GMF branch\n",
        "        gmf_out = user_z * item_z  # pure element-wise product\n",
        "\n",
        "        # MLP branch\n",
        "        mlp_input = torch.cat([user_z, item_z], dim=1)\n",
        "        mlp_out = self.mlp(mlp_input)\n",
        "\n",
        "        # Final prediction\n",
        "        concat = torch.cat([gmf_out, mlp_out], dim=1)\n",
        "        logits = self.output(concat)\n",
        "\n",
        "        # Return logits (use BCEWithLogitsLoss)\n",
        "        return logits.squeeze(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HybridAutoRecNCF(nn.Module):\n",
        "    def __init__(self, num_users, num_items, latent_dim, mlp_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        self.user_autorec = AutoEncoder(num_items, latent_dim)\n",
        "        self.item_autorec = AutoEncoder(num_users, latent_dim)\n",
        "\n",
        "        self.ncf = NCF(latent_dim, mlp_layers)\n",
        "\n",
        "    def forward(self, user_vecs, item_vecs, user_ids, item_ids):\n",
        "        # AutoRec forward\n",
        "        # user_vecs: (batch_size, num_items) - each row is a user's interaction vector\n",
        "        # item_vecs: (batch_size, num_users) - each row is an item's interaction vector\n",
        "        user_recon, user_z = self.user_autorec(user_vecs)\n",
        "        item_recon, item_z = self.item_autorec(item_vecs)\n",
        "\n",
        "        # Each element in the batch corresponds to a (user, item) pair\n",
        "        # user_z[i] is the latent for the user in pair i\n",
        "        # item_z[i] is the latent for the item in pair i\n",
        "        pred = self.ncf(user_z, item_z)\n",
        "        return pred, user_recon, item_recon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reconstruction_loss(pred, target, mask):\n",
        "    \"\"\"Binary cross-entropy loss for reconstruction (implicit feedback)\"\"\"\n",
        "    # pred and target are in [0, 1] (sigmoid output)\n",
        "    # mask indicates which elements to consider\n",
        "    bce = F.binary_cross_entropy(pred, target, reduction='none')\n",
        "    return (bce * mask).sum() / mask.sum()\n",
        "\n",
        "\n",
        "def interaction_loss(pred_logits, labels):\n",
        "    \"\"\"Binary cross-entropy loss for interaction prediction\"\"\"\n",
        "    return F.binary_cross_entropy_with_logits(pred_logits, labels.float())\n",
        "\n",
        "\n",
        "def total_loss(pred_logits, labels,\n",
        "               user_recon, user_vecs, user_mask,\n",
        "               item_recon, item_vecs, item_mask,\n",
        "               alpha=1.0, beta=1.0):\n",
        "    rec_u = reconstruction_loss(user_recon, user_vecs, user_mask)\n",
        "    rec_i = reconstruction_loss(item_recon, item_vecs, item_mask)\n",
        "    inter = interaction_loss(pred_logits, labels)\n",
        "    return alpha * (rec_u + rec_i) + beta * inter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, dataloader, optimizer, device):\n",
        "    model.train()\n",
        "    total = 0.0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        (user_ids, item_ids, labels,\n",
        "         user_vecs, item_vecs,\n",
        "         user_mask, item_mask) = batch\n",
        "\n",
        "        user_ids = user_ids.to(device).squeeze()\n",
        "        item_ids = item_ids.to(device).squeeze()\n",
        "        labels = labels.to(device).squeeze()\n",
        "        user_vecs = user_vecs.to(device)\n",
        "        item_vecs = item_vecs.to(device)\n",
        "        user_mask = user_mask.to(device)\n",
        "        item_mask = item_mask.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        pred_logits, user_recon, item_recon = model(\n",
        "            user_vecs, item_vecs, user_ids, item_ids\n",
        "        )\n",
        "\n",
        "        loss = total_loss(\n",
        "            pred_logits, labels,\n",
        "            user_recon, user_vecs, user_mask,\n",
        "            item_recon, item_vecs, item_mask\n",
        "        )\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total += loss.item()\n",
        "\n",
        "    return total / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Dataset already exists at /Users/abbas/Documents/Codes/thesis/recommender/src/../data/ml-1m/ratings.dat\n",
            "✓ Training matrix created: 460225 interactions\n",
            "Loading training data from /Users/abbas/Documents/Codes/thesis/recommender/src/../data/ml-1m.train.rating...\n",
            "✓ Loaded 460225 training pairs\n",
            "  - Users: 6038\n",
            "  - Items: 3533\n",
            "✓ Extracted 115056 positive test samples\n",
            "  - Test negatives will be generated on-the-fly during evaluation\n"
          ]
        }
      ],
      "source": [
        "# Paths and hyperparameters (same as NCF)\n",
        "DATA_DIR = os.path.join(os.path.dirname(os.getcwd()), '..', 'data')\n",
        "MODEL_PATH = os.path.join(os.path.dirname(os.getcwd()), '..', 'models')\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_PATH, exist_ok=True)\n",
        "\n",
        "# Hyperparameters (same as NCF)\n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 50\n",
        "TOP_K = 10\n",
        "NUM_NG = 4  # Number of negatives per positive during training\n",
        "TEST_NUM_NG = 99  # Number of negatives per positive during testing\n",
        "EARLY_STOPPING_PATIENCE = 10\n",
        "MIN_DELTA = 0.0001\n",
        "\n",
        "# Evaluation settings (for faster training)\n",
        "# Reduce MAX_TEST_SAMPLES to speed up evaluation (None = all 115k samples, very slow)\n",
        "# Recommended: 1000-3000 for fast training, 5000+ for more accurate metrics\n",
        "MAX_TEST_SAMPLES = 2000  # Maximum test samples to evaluate per epoch (None = all, but slower)\n",
        "EVAL_EVERY_N_EPOCHS = 1  # Evaluate every N epochs (1 = every epoch, 2 = every 2 epochs, etc.)\n",
        "\n",
        "# Download and preprocess (exactly same as NCF)\n",
        "ratings_file = download_ml1m_dataset(DATA_DIR)\n",
        "\n",
        "# Preprocess to NCF format (filters ratings >= 4, creates train/test split)\n",
        "train_rating_path, test_rating_path, test_negative_path, user_num, item_num, train_mat = \\\n",
        "    preprocess_ml1m_to_ncf_format(ratings_file, data_dir=DATA_DIR, test_negatives=TEST_NUM_NG)\n",
        "\n",
        "# Load data (exactly same as NCF)\n",
        "train_data, test_data_full, user_num, item_num, train_mat = load_all_data(\n",
        "    train_rating_path, test_negative_path\n",
        ")\n",
        "\n",
        "# Extract only positive test samples and load negatives for on-the-fly generation\n",
        "# test_data_full from load_all_data contains: [pos1, neg1, neg2, ..., neg99, pos2, neg1, ...]\n",
        "# We need to extract only the positive samples (every TEST_NUM_NG+1 samples)\n",
        "test_data_positives = []\n",
        "test_negative_samples = {}\n",
        "\n",
        "# Read test negative file directly to get positive samples and their negatives\n",
        "with open(test_negative_path, 'r') as f:\n",
        "    for line in f:\n",
        "        arr = line.strip().split('\\t')\n",
        "        if not arr[0]:  # Skip empty lines\n",
        "            continue\n",
        "        positive_pair = eval(arr[0])\n",
        "        u, i = positive_pair[0], positive_pair[1]\n",
        "        test_data_positives.append([u, i])\n",
        "        negatives = [int(neg) for neg in arr[1:] if neg]\n",
        "        test_negative_samples[(u, i)] = negatives\n",
        "\n",
        "print(f\"✓ Extracted {len(test_data_positives)} positive test samples\")\n",
        "print(f\"  - Test negatives will be generated on-the-fly during evaluation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Data loaded and preprocessed\n",
            "  - Users: 6038\n",
            "  - Items: 3533\n",
            "  - Training interactions: 460,225\n",
            "  - Test positive samples: 115,056\n",
            "  - Test samples per evaluation: 11,505,600 (generated on-the-fly)\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Data is already preprocessed (ratings >= 4 filtered, train/test split done)\n",
        "# train_mat is a sparse matrix of shape (user_num, item_num)\n",
        "# Convert to dense for AutoEncoder input\n",
        "train_mat_dense = train_mat.toarray().astype(np.float32)\n",
        "\n",
        "print(f\"✓ Data loaded and preprocessed\")\n",
        "print(f\"  - Users: {user_num}\")\n",
        "print(f\"  - Items: {item_num}\")\n",
        "print(f\"  - Training interactions: {train_mat.nnz:,}\")\n",
        "print(f\"  - Test positive samples: {len(test_data_positives):,}\")\n",
        "print(f\"  - Test samples per evaluation: {len(test_data_positives) * (TEST_NUM_NG + 1):,} (generated on-the-fly)\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create test matrix for evaluation (only positive interactions)\n",
        "test_mat = sp.dok_matrix((user_num, item_num), dtype=np.float32)\n",
        "for u, i in train_data:  # train_data contains positive pairs\n",
        "    if (u, i) not in train_mat:  # Only add if not in training\n",
        "        test_mat[u, i] = 1.0\n",
        "\n",
        "test_mat_dense = test_mat.toarray().astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n",
            "✓ Datasets created\n",
            "  - Train samples: 2,301,125\n",
            "  - Test positive samples: 115,056\n",
            "  - Test samples per evaluation: 11,505,600 (generated on-the-fly)\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Dataset class for hybrid model (similar to NCFData but with full vectors)\n",
        "class HybridRankingDataset(data.Dataset):\n",
        "    def __init__(self, features, num_item, train_mat_dense, train_mat_sparse=None, num_ng=0, is_training=None, test_negative_samples=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            features: List of [user, item] pairs (positive samples)\n",
        "            num_item: Total number of items\n",
        "            train_mat_dense: Dense interaction matrix (num_users, num_items) for AutoEncoder input\n",
        "            train_mat_sparse: Sparse matrix for checking if (user, item) exists (for negative sampling)\n",
        "            num_ng: Number of negative samples per positive\n",
        "            is_training: Whether this is training data (needs negative sampling)\n",
        "            test_negative_samples: Dict mapping (user, item) -> list of negative items (for test set)\n",
        "        \"\"\"\n",
        "        super(HybridRankingDataset, self).__init__()\n",
        "        \n",
        "        self.features_ps = features  # Positive samples\n",
        "        self.num_item = num_item\n",
        "        self.train_mat_dense = train_mat_dense\n",
        "        self.train_mat_sparse = train_mat_sparse if train_mat_sparse is not None else train_mat_dense\n",
        "        self.num_ng = num_ng\n",
        "        self.is_training = is_training\n",
        "        self.test_negative_samples = test_negative_samples  # For on-the-fly negative generation\n",
        "        \n",
        "        # Create masks (1 where interaction exists, 0 otherwise)\n",
        "        self.user_mask = (train_mat_dense > 0).astype(np.float32)\n",
        "        self.item_mask = (train_mat_dense.T > 0).astype(np.float32)\n",
        "        \n",
        "        # Initialize labels\n",
        "        self.labels = [0 for _ in range(len(features))]\n",
        "        \n",
        "        # These will be populated by ng_sample() during training\n",
        "        self.features_ng = []\n",
        "        self.features_fill = []\n",
        "        self.labels_fill = []\n",
        "    \n",
        "    def ng_sample(self):\n",
        "        \"\"\"Generate negative samples for training (same as NCFData) - called per epoch\"\"\"\n",
        "        assert self.is_training, 'Negative sampling only needed during training'\n",
        "        \n",
        "        self.features_ng = []\n",
        "        \n",
        "        # For each positive pair, generate num_ng negative samples\n",
        "        for x in self.features_ps:\n",
        "            u = x[0]  # User ID\n",
        "            # Generate num_ng negative items for this user\n",
        "            for t in range(self.num_ng):\n",
        "                # Sample a random item\n",
        "                j = np.random.randint(self.num_item)\n",
        "                \n",
        "                # Make sure this item is NOT in the user's training set\n",
        "                # Keep sampling until we find a negative item\n",
        "                while (u, j) in self.train_mat_sparse:\n",
        "                    j = np.random.randint(self.num_item)\n",
        "                \n",
        "                # Add this negative sample\n",
        "                self.features_ng.append([u, j])\n",
        "        \n",
        "        # Create labels: 1 for positives, 0 for negatives\n",
        "        labels_ps = [1 for _ in range(len(self.features_ps))]\n",
        "        labels_ng = [0 for _ in range(len(self.features_ng))]\n",
        "        \n",
        "        # Combine positives and negatives\n",
        "        self.features_fill = self.features_ps + self.features_ng\n",
        "        self.labels_fill = labels_ps + labels_ng\n",
        "        \n",
        "        print(f\"✓ Generated {len(self.features_ng)} negative samples\")\n",
        "        print(f\"  - Total samples (positives + negatives): {len(self.features_fill)}\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        if self.is_training:\n",
        "            return (self.num_ng + 1) * len(self.labels) if self.features_fill else 0\n",
        "        else:\n",
        "            # For test set, return number of positive samples\n",
        "            # Negatives will be generated on-the-fly during __getitem__\n",
        "            return len(self.features_ps)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if self.is_training:\n",
        "            # During training: use combined features (positives + negatives)\n",
        "            features = self.features_fill\n",
        "            labels = self.labels_fill\n",
        "            user = features[idx][0]\n",
        "            item = features[idx][1]\n",
        "            label = labels[idx]\n",
        "        else:\n",
        "            # During testing: generate negatives on-the-fly\n",
        "            # idx corresponds to a positive test sample\n",
        "            user, item = self.features_ps[idx]\n",
        "            label = 1.0  # Positive sample\n",
        "            \n",
        "            # Get negatives for this user-item pair\n",
        "            if self.test_negative_samples and (user, item) in self.test_negative_samples:\n",
        "                negatives = self.test_negative_samples[(user, item)]\n",
        "            else:\n",
        "                # Fallback: generate negatives on-the-fly if not in dict\n",
        "                negatives = []\n",
        "                attempts = 0\n",
        "                max_attempts = self.num_ng * 10\n",
        "                while len(negatives) < self.num_ng and attempts < max_attempts:\n",
        "                    neg_item = np.random.randint(self.num_item)\n",
        "                    if (user, neg_item) not in self.train_mat_sparse:\n",
        "                        negatives.append(neg_item)\n",
        "                    attempts += 1\n",
        "        \n",
        "        # Get user vector (interactions across all items)\n",
        "        user_vec = torch.FloatTensor(self.train_mat_dense[user])\n",
        "        \n",
        "        # Get item vector (interactions across all users)\n",
        "        item_vec = torch.FloatTensor(self.train_mat_dense[:, item])\n",
        "        \n",
        "        # Get masks\n",
        "        user_mask = torch.FloatTensor(self.user_mask[user])\n",
        "        item_mask = torch.FloatTensor(self.item_mask[item])\n",
        "        \n",
        "        return (\n",
        "            torch.LongTensor([user]),\n",
        "            torch.LongTensor([item]),\n",
        "            torch.FloatTensor([label]),\n",
        "            user_vec,\n",
        "            item_vec,\n",
        "            user_mask,\n",
        "            item_mask\n",
        "        )\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = HybridRankingDataset(\n",
        "    train_data,\n",
        "    item_num,\n",
        "    train_mat_dense,\n",
        "    train_mat,\n",
        "    num_ng=NUM_NG,\n",
        "    is_training=True\n",
        ")\n",
        "\n",
        "# Test dataset: only store positive samples, generate negatives on-the-fly\n",
        "test_dataset = HybridRankingDataset(\n",
        "    test_data_positives,  # Only positive samples\n",
        "    item_num,\n",
        "    train_mat_dense,\n",
        "    train_mat,\n",
        "    num_ng=TEST_NUM_NG,  # Number of negatives to generate per positive\n",
        "    is_training=False,\n",
        "    test_negative_samples=test_negative_samples  # Pre-loaded negatives\n",
        ")\n",
        "\n",
        "# Generate negative samples for training (will be regenerated each epoch)\n",
        "train_dataset.ng_sample()\n",
        "\n",
        "print(f\"✓ Datasets created\")\n",
        "print(f\"  - Train samples: {len(train_dataset):,}\")\n",
        "print(f\"  - Test positive samples: {len(test_dataset):,}\")\n",
        "print(f\"  - Test samples per evaluation: {len(test_dataset) * (TEST_NUM_NG + 1):,} (generated on-the-fly)\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Data loaders created\n",
            "  - Train batch size: 256\n",
            "  - Test: 115056 positive samples (negatives generated on-the-fly)\n",
            "  - Test batch size: 100 (1 positive + 99 negatives per user)\n"
          ]
        }
      ],
      "source": [
        "# Create data loaders (exactly same as NCF)\n",
        "train_loader = data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=True if torch.cuda.is_available() else False\n",
        ")\n",
        "\n",
        "# For test loader, we need to create batches that include negatives\n",
        "# Each batch should contain 1 positive + TEST_NUM_NG negatives for a user\n",
        "class TestDataLoader:\n",
        "    \"\"\"Custom test data loader that generates negatives on-the-fly\"\"\"\n",
        "    def __init__(self, test_dataset, batch_size=1):\n",
        "        self.test_dataset = test_dataset\n",
        "        self.batch_size = batch_size  # Number of users per batch\n",
        "        self.num_positives = len(test_dataset)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.num_positives  # One batch per positive test sample\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for idx in range(self.num_positives):\n",
        "            # Get positive sample\n",
        "            user, item, label, user_vec, item_vec, user_mask, item_mask = self.test_dataset[idx]\n",
        "            \n",
        "            # Get negatives for this user-item pair\n",
        "            user_id = user.item()\n",
        "            item_id = item.item()\n",
        "            \n",
        "            if self.test_dataset.test_negative_samples and (user_id, item_id) in self.test_dataset.test_negative_samples:\n",
        "                negatives = self.test_dataset.test_negative_samples[(user_id, item_id)]\n",
        "            else:\n",
        "                # Fallback: generate negatives\n",
        "                negatives = []\n",
        "                attempts = 0\n",
        "                while len(negatives) < self.test_dataset.num_ng and attempts < self.test_dataset.num_ng * 10:\n",
        "                    neg_item = np.random.randint(self.test_dataset.num_item)\n",
        "                    if (user_id, neg_item) not in self.test_dataset.train_mat_sparse:\n",
        "                        negatives.append(neg_item)\n",
        "                    attempts += 1\n",
        "            \n",
        "            # Create batch: [positive, neg1, neg2, ..., neg99]\n",
        "            batch_users = [user_id] + [user_id] * len(negatives)\n",
        "            batch_items = [item_id] + negatives\n",
        "            batch_labels = [1.0] + [0.0] * len(negatives)\n",
        "            \n",
        "            # Get vectors for all items in batch\n",
        "            batch_user_vecs = []\n",
        "            batch_item_vecs = []\n",
        "            batch_user_masks = []\n",
        "            batch_item_masks = []\n",
        "            \n",
        "            for u, i in zip(batch_users, batch_items):\n",
        "                u_vec = torch.FloatTensor(self.test_dataset.train_mat_dense[u])\n",
        "                i_vec = torch.FloatTensor(self.test_dataset.train_mat_dense[:, i])\n",
        "                u_mask = torch.FloatTensor(self.test_dataset.user_mask[u])\n",
        "                i_mask = torch.FloatTensor(self.test_dataset.item_mask[i])\n",
        "                \n",
        "                batch_user_vecs.append(u_vec)\n",
        "                batch_item_vecs.append(i_vec)\n",
        "                batch_user_masks.append(u_mask)\n",
        "                batch_item_masks.append(i_mask)\n",
        "            \n",
        "            yield (\n",
        "                torch.LongTensor(batch_users),\n",
        "                torch.LongTensor(batch_items),\n",
        "                torch.FloatTensor(batch_labels),\n",
        "                torch.stack(batch_user_vecs),\n",
        "                torch.stack(batch_item_vecs),\n",
        "                torch.stack(batch_user_masks),\n",
        "                torch.stack(batch_item_masks)\n",
        "            )\n",
        "\n",
        "test_loader = TestDataLoader(test_dataset, batch_size=1)\n",
        "\n",
        "print(f\"✓ Data loaders created\")\n",
        "print(f\"  - Train batch size: {BATCH_SIZE}\")\n",
        "print(f\"  - Test: {len(test_dataset)} positive samples (negatives generated on-the-fly)\")\n",
        "print(f\"  - Test batch size: {TEST_NUM_NG + 1} (1 positive + {TEST_NUM_NG} negatives per user)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Model initialized\n",
            "  - Users: 6038, Items: 3533\n",
            "  - Latent dim: 64\n",
            "  - MLP layers: [128, 64]\n",
            "  - Total parameters: 5,100,324\n"
          ]
        }
      ],
      "source": [
        "# Initialize model and optimizer\n",
        "latent_dim = 64\n",
        "mlp_layers = [128, 64]\n",
        "\n",
        "model = HybridAutoRecNCF(\n",
        "    user_num, item_num, latent_dim, mlp_layers\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5\n",
        ")\n",
        "\n",
        "print(f\"✓ Model initialized\")\n",
        "print(f\"  - Users: {user_num}, Items: {item_num}\")\n",
        "print(f\"  - Latent dim: {latent_dim}\")\n",
        "print(f\"  - MLP layers: {mlp_layers}\")\n",
        "print(f\"  - Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extended evaluation function with detailed metrics (for visualization)\n",
        "def evaluate_ranking_metrics_detailed(model, train_mat_dense, test_mat_dense, num_users, num_items, top_k=10, device=None):\n",
        "    \"\"\"Extended version that returns detailed user-level metrics\"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    model.eval()\n",
        "    train_mat_tensor = torch.FloatTensor(train_mat_dense).to(device)\n",
        "    test_mat_np = test_mat_dense\n",
        "    train_mask = (train_mat_dense > 0)\n",
        "    \n",
        "    batch_size_users = 256\n",
        "    predictions = np.zeros((num_users, num_items), dtype=np.float32)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for start_idx in range(0, num_users, batch_size_users):\n",
        "            end_idx = min(start_idx + batch_size_users, num_users)\n",
        "            batch_size = end_idx - start_idx\n",
        "            user_vecs_batch = train_mat_tensor[start_idx:end_idx]\n",
        "            \n",
        "            for item_id in range(num_items):\n",
        "                item_vec_full = train_mat_tensor[:, item_id]\n",
        "                item_vecs_batch = item_vec_full.unsqueeze(0).expand(batch_size, -1)\n",
        "                user_ids_batch = torch.arange(start_idx, end_idx, device=device)\n",
        "                item_ids_batch = torch.full((batch_size,), item_id, device=device)\n",
        "                pred_batch, _, _ = model(user_vecs_batch, item_vecs_batch, user_ids_batch, item_ids_batch)\n",
        "                predictions[start_idx:end_idx, item_id] = pred_batch.cpu().numpy()\n",
        "    \n",
        "    predictions = predictions * (~train_mask).astype(np.float32) - train_mask.astype(np.float32) * 1e10\n",
        "    \n",
        "    HR_list = []\n",
        "    NDCG_list = []\n",
        "    user_test_counts = []\n",
        "    \n",
        "    for user_id in range(num_users):\n",
        "        test_items = set(np.where(test_mat_np[user_id] > 0)[0])\n",
        "        if len(test_items) == 0:\n",
        "            continue\n",
        "        \n",
        "        user_predictions = predictions[user_id]\n",
        "        top_k_indices = np.argsort(user_predictions)[-top_k:][::-1]\n",
        "        top_k_items = top_k_indices.tolist()\n",
        "        \n",
        "        user_hr = []\n",
        "        user_ndcg = []\n",
        "        for test_item in test_items:\n",
        "            user_hr.append(hit(test_item, top_k_items))\n",
        "            user_ndcg.append(ndcg(test_item, top_k_items))\n",
        "        \n",
        "        HR_list.append(np.mean(user_hr) if user_hr else 0.0)\n",
        "        NDCG_list.append(np.mean(user_ndcg) if user_ndcg else 0.0)\n",
        "        user_test_counts.append(len(test_items))\n",
        "    \n",
        "    if len(HR_list) == 0:\n",
        "        return 0.0, 0.0, {}\n",
        "    \n",
        "    details = {\n",
        "        'user_hr': HR_list,\n",
        "        'user_ndcg': NDCG_list,\n",
        "        'user_test_counts': user_test_counts,\n",
        "        'predictions': predictions\n",
        "    }\n",
        "    \n",
        "    return np.mean(HR_list), np.mean(NDCG_list), details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation function (same format as NCF)\n",
        "def evaluate_metrics(model, test_loader, top_k, device='cuda', max_test_samples=None):\n",
        "    \"\"\"\n",
        "    Evaluate HR@K and NDCG@K (same as NCF evaluation)\n",
        "    \n",
        "    Args:\n",
        "        model: The model to evaluate\n",
        "        test_loader: Test data loader\n",
        "        top_k: Top-K for ranking metrics\n",
        "        device: Device to run evaluation on\n",
        "        max_test_samples: Maximum number of test samples to evaluate (None = all, for speed)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    HR_list = []\n",
        "    NDCG_list = []\n",
        "    \n",
        "    # Limit number of test samples for faster evaluation\n",
        "    test_samples_processed = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(test_loader):\n",
        "            # Stop if we've processed enough samples\n",
        "            if max_test_samples is not None and test_samples_processed >= max_test_samples:\n",
        "                break\n",
        "                \n",
        "            (user_ids, item_ids, labels,\n",
        "             user_vecs, item_vecs,\n",
        "             user_mask, item_mask) = batch\n",
        "            \n",
        "            # Move to device\n",
        "            user_ids = user_ids.to(device)\n",
        "            item_ids = item_ids.to(device)\n",
        "            user_vecs = user_vecs.to(device)\n",
        "            item_vecs = item_vecs.to(device)\n",
        "            \n",
        "            # Get predictions\n",
        "            pred_logits, _, _ = model(user_vecs, item_vecs, user_ids, item_ids)\n",
        "            predictions = pred_logits\n",
        "            \n",
        "            # Get top-K items (from this batch which contains 1 positive + negatives)\n",
        "            _, indices = torch.topk(predictions, min(top_k, len(predictions)))\n",
        "            \n",
        "            # Get the actual item IDs for top-K recommendations\n",
        "            recommends = torch.take(item_ids, indices).cpu().numpy().tolist()\n",
        "            \n",
        "            # Ground truth item is the first one (positive sample, label=1.0)\n",
        "            gt_item = item_ids[0].item()\n",
        "            \n",
        "            HR_list.append(hit(gt_item, recommends))\n",
        "            NDCG_list.append(ndcg(gt_item, recommends))\n",
        "            \n",
        "            test_samples_processed += 1\n",
        "    \n",
        "    mean_HR = np.mean(HR_list) if HR_list else 0.0\n",
        "    mean_NDCG = np.mean(NDCG_list) if NDCG_list else 0.0\n",
        "    \n",
        "    return mean_HR, mean_NDCG\n",
        "\n",
        "# Extended evaluation function for detailed metrics\n",
        "def evaluate_ranking_metrics_detailed(model, train_mat_dense, test_mat, num_users, num_items, top_k=10, device=None):\n",
        "    \"\"\"\n",
        "    Evaluate HitRate@K and NDCG@K metrics.\n",
        "    \n",
        "    For each user:\n",
        "    1. Get predictions for all items using training data\n",
        "    2. Mask out items seen in training\n",
        "    3. Get top-K items\n",
        "    4. Calculate HR and NDCG based on test items\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    # Convert to tensors\n",
        "    train_mat_tensor = torch.FloatTensor(train_mat_dense).to(device)\n",
        "    test_mat_np = test_mat_dense\n",
        "    \n",
        "    # Get training mask\n",
        "    train_mask = (train_mat_dense > 0)\n",
        "    \n",
        "    # Predict scores for all user-item pairs\n",
        "    batch_size_users = 256\n",
        "    predictions = np.zeros((num_users, num_items), dtype=np.float32)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for start_idx in range(0, num_users, batch_size_users):\n",
        "            end_idx = min(start_idx + batch_size_users, num_users)\n",
        "            batch_size = end_idx - start_idx\n",
        "            \n",
        "            # Get user vectors (interactions across all items from training)\n",
        "            user_vecs_batch = train_mat_tensor[start_idx:end_idx]  # (batch_size, num_items)\n",
        "            \n",
        "            # For each item, get its interaction vector across all users\n",
        "            for item_id in range(num_items):\n",
        "                # Get item vector (interactions across all users from training)\n",
        "                item_vec_full = train_mat_tensor[:, item_id]  # (num_users,)\n",
        "                # Expand to match batch size\n",
        "                item_vecs_batch = item_vec_full.unsqueeze(0).expand(batch_size, -1)  # (batch_size, num_users)\n",
        "                \n",
        "                # Create dummy user_ids and item_ids\n",
        "                user_ids_batch = torch.arange(start_idx, end_idx, device=device)\n",
        "                item_ids_batch = torch.full((batch_size,), item_id, device=device)\n",
        "                \n",
        "                # Get predictions (logits)\n",
        "                pred_batch, _, _ = model(\n",
        "                    user_vecs_batch, item_vecs_batch, user_ids_batch, item_ids_batch\n",
        "                )\n",
        "                \n",
        "                predictions[start_idx:end_idx, item_id] = pred_batch.cpu().numpy()\n",
        "    \n",
        "    # Mask out items seen in training\n",
        "    predictions = predictions * (~train_mask).astype(np.float32) - train_mask.astype(np.float32) * 1e10\n",
        "    \n",
        "    HR_list = []\n",
        "    NDCG_list = []\n",
        "    \n",
        "    # Calculate metrics for each user\n",
        "    for user_id in range(num_users):\n",
        "        # Get ground truth items for this user (items interacted with in test set)\n",
        "        test_items = set(np.where(test_mat_np[user_id] > 0)[0])\n",
        "        \n",
        "        # Skip if user has no test items\n",
        "        if len(test_items) == 0:\n",
        "            continue\n",
        "        \n",
        "        # Get top-K items for this user\n",
        "        user_predictions = predictions[user_id]\n",
        "        top_k_indices = np.argsort(user_predictions)[-top_k:][::-1]\n",
        "        top_k_items = top_k_indices.tolist()\n",
        "        \n",
        "        # Calculate metrics for each test item\n",
        "        user_hr = []\n",
        "        user_ndcg = []\n",
        "        for test_item in test_items:\n",
        "            user_hr.append(hit(test_item, top_k_items))\n",
        "            user_ndcg.append(ndcg(test_item, top_k_items))\n",
        "        \n",
        "        # Average over test items for this user\n",
        "        HR_list.append(np.mean(user_hr) if user_hr else 0.0)\n",
        "        NDCG_list.append(np.mean(user_ndcg) if user_ndcg else 0.0)\n",
        "    \n",
        "    # Calculate average metrics\n",
        "    if len(HR_list) == 0:\n",
        "        return 0.0, 0.0\n",
        "    \n",
        "    mean_HR = np.mean(HR_list)\n",
        "    mean_NDCG = np.mean(NDCG_list)\n",
        "    \n",
        "    return mean_HR, mean_NDCG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "Starting Training\n",
            "======================================================================\n",
            "Epochs: 50\n",
            "Batch size: 256\n",
            "Learning rate: 0.001\n",
            "Top-K for ranking metrics: 10\n",
            "Training negatives per positive: 4\n",
            "Test negatives per positive: 99\n",
            "======================================================================\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  ✓ New best model! (HR@10: 0.7300)\n",
            "  ✓ Model saved to /Users/abbas/Documents/Codes/thesis/recommender/src/../models/HybridAutoRecNCF-Ranking.pth\n",
            "  Time: 00:05:17\n",
            "  Loss: 0.2987\n",
            "  HR@10: 0.7300\n",
            "  NDCG@10: 0.4535\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 00:05:16\n",
            "  Loss: 0.2822\n",
            "  HR@10: 0.7230\n",
            "  NDCG@10: 0.4469\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 00:05:14\n",
            "  Loss: 0.2788\n",
            "  HR@10: 0.7270\n",
            "  NDCG@10: 0.4531\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  ✓ New best model! (HR@10: 0.7370)\n",
            "  ✓ Model saved to /Users/abbas/Documents/Codes/thesis/recommender/src/../models/HybridAutoRecNCF-Ranking.pth\n",
            "  Time: 00:05:13\n",
            "  Loss: 0.2765\n",
            "  HR@10: 0.7370\n",
            "  NDCG@10: 0.4595\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 00:05:21\n",
            "  Loss: 0.2755\n",
            "  HR@10: 0.7295\n",
            "  NDCG@10: 0.4551\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 00:05:12\n",
            "  Loss: 0.2739\n",
            "  HR@10: 0.7345\n",
            "  NDCG@10: 0.4617\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  ✓ New best model! (HR@10: 0.7380)\n",
            "  ✓ Model saved to /Users/abbas/Documents/Codes/thesis/recommender/src/../models/HybridAutoRecNCF-Ranking.pth\n",
            "  Time: 00:05:16\n",
            "  Loss: 0.2733\n",
            "  HR@10: 0.7380\n",
            "  NDCG@10: 0.4633\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 00:05:17\n",
            "  Loss: 0.2730\n",
            "  HR@10: 0.7365\n",
            "  NDCG@10: 0.4598\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                    \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 02:15:21\n",
            "  Loss: 0.2727\n",
            "  HR@10: 0.7315\n",
            "  NDCG@10: 0.4577\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 00:05:11\n",
            "  Loss: 0.2719\n",
            "  HR@10: 0.7340\n",
            "  NDCG@10: 0.4568\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 00:05:07\n",
            "  Loss: 0.2712\n",
            "  HR@10: 0.7300\n",
            "  NDCG@10: 0.4609\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  ✓ New best model! (HR@10: 0.7420)\n",
            "  ✓ Model saved to /Users/abbas/Documents/Codes/thesis/recommender/src/../models/HybridAutoRecNCF-Ranking.pth\n",
            "  Time: 00:05:33\n",
            "  Loss: 0.2710\n",
            "  HR@10: 0.7420\n",
            "  NDCG@10: 0.4599\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 00:05:38\n",
            "  Loss: 0.2709\n",
            "  HR@10: 0.7380\n",
            "  NDCG@10: 0.4650\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 00:05:09\n",
            "  Loss: 0.2707\n",
            "  HR@10: 0.7410\n",
            "  NDCG@10: 0.4644\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  ✓ New best model! (HR@10: 0.7455)\n",
            "  ✓ Model saved to /Users/abbas/Documents/Codes/thesis/recommender/src/../models/HybridAutoRecNCF-Ranking.pth\n",
            "  Time: 00:05:09\n",
            "  Loss: 0.2701\n",
            "  HR@10: 0.7455\n",
            "  NDCG@10: 0.4638\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 00:05:28\n",
            "  Loss: 0.2699\n",
            "  HR@10: 0.7390\n",
            "  NDCG@10: 0.4680\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 00:05:27\n",
            "  Loss: 0.2700\n",
            "  HR@10: 0.7415\n",
            "  NDCG@10: 0.4657\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 00:05:21\n",
            "  Loss: 0.2696\n",
            "  HR@10: 0.7370\n",
            "  NDCG@10: 0.4645\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 00:05:39\n",
            "  Loss: 0.2698\n",
            "  HR@10: 0.7435\n",
            "  NDCG@10: 0.4695\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  ✓ New best model! (HR@10: 0.7460)\n",
            "  ✓ Model saved to /Users/abbas/Documents/Codes/thesis/recommender/src/../models/HybridAutoRecNCF-Ranking.pth\n",
            "  Time: 00:05:26\n",
            "  Loss: 0.2690\n",
            "  HR@10: 0.7460\n",
            "  NDCG@10: 0.4668\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 00:05:09\n",
            "  Loss: 0.2692\n",
            "  HR@10: 0.7385\n",
            "  NDCG@10: 0.4604\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 00:05:22\n",
            "  Loss: 0.2694\n",
            "  HR@10: 0.7375\n",
            "  NDCG@10: 0.4606\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 00:05:01\n",
            "  Loss: 0.2688\n",
            "  HR@10: 0.7445\n",
            "  NDCG@10: 0.4680\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 00:05:56\n",
            "  Loss: 0.2683\n",
            "  HR@10: 0.7425\n",
            "  NDCG@10: 0.4613\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 00:05:28\n",
            "  Loss: 0.2687\n",
            "  HR@10: 0.7440\n",
            "  NDCG@10: 0.4623\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Evaluating on test set (max 2000 samples)...\n",
            "  Time: 00:06:00\n",
            "  Loss: 0.2684\n",
            "  HR@10: 0.7330\n",
            "  NDCG@10: 0.4597\n",
            "----------------------------------------------------------------------\n",
            "✓ Generated 1840900 negative samples\n",
            "  - Total samples (positives + negatives): 2301125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/50:  72%|███████▏  | 6502/8989 [04:04<02:00, 20.65it/s]"
          ]
        }
      ],
      "source": [
        "# Training loop (same structure as NCF)\n",
        "loss_function = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Ensure total_loss is the function, not a variable\n",
        "# This prevents issues if total_loss was accidentally assigned as a float in a previous run\n",
        "if not callable(total_loss):\n",
        "    raise RuntimeError(\"total_loss is not callable! Please re-run cell 5 to define the total_loss function.\")\n",
        "\n",
        "best_hr = 0.0\n",
        "best_ndcg = 0.0\n",
        "best_epoch = 0\n",
        "patience_counter = 0\n",
        "\n",
        "# Create model save directory\n",
        "model_path = os.path.join(MODEL_PATH, 'HybridAutoRecNCF-Ranking.pth')\n",
        "\n",
        "# Track metrics for visualization\n",
        "training_history = {\n",
        "    'epoch': [],\n",
        "    'train_loss': [],\n",
        "    'hit_rate': [],\n",
        "    'ndcg': []\n",
        "}\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Starting Training\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Epochs: {EPOCHS}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"Top-K for ranking metrics: {TOP_K}\")\n",
        "print(f\"Training negatives per positive: {NUM_NG}\")\n",
        "print(f\"Test negatives per positive: {TEST_NUM_NG}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Training\n",
        "\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss_sum = 0.0\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Regenerate negative samples each epoch (same as NCF)\n",
        "    train_dataset.ng_sample()\n",
        "    \n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False):\n",
        "        (user_ids, item_ids, labels,\n",
        "         user_vecs, item_vecs,\n",
        "         user_mask, item_mask) = batch\n",
        "\n",
        "        user_ids = user_ids.to(device).squeeze()\n",
        "        item_ids = item_ids.to(device).squeeze()\n",
        "        labels = labels.to(device).squeeze()\n",
        "        user_vecs = user_vecs.to(device)\n",
        "        item_vecs = item_vecs.to(device)\n",
        "        user_mask = user_mask.to(device)\n",
        "        item_mask = item_mask.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        pred_logits, user_recon, item_recon = model(\n",
        "            user_vecs, item_vecs, user_ids, item_ids\n",
        "        )\n",
        "\n",
        "        loss = total_loss(\n",
        "            pred_logits, labels,\n",
        "            user_recon, user_vecs, user_mask,\n",
        "            item_recon, item_vecs, item_mask\n",
        "        )\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss_sum += loss.item()\n",
        "    \n",
        "    train_loss = epoch_loss_sum / len(train_loader)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    \n",
        "    # Evaluation (same as NCF) - only evaluate every N epochs or on first/last epoch\n",
        "    should_evaluate = (epoch + 1) % EVAL_EVERY_N_EPOCHS == 0 or epoch == 0 or epoch == EPOCHS - 1\n",
        "    \n",
        "    if should_evaluate:\n",
        "        print(f\"  Evaluating on test set (max {MAX_TEST_SAMPLES} samples)...\")\n",
        "        eval_start = time.time()\n",
        "        hit_rate, ndcg_score = evaluate_metrics(\n",
        "            model, test_loader, TOP_K, device=device, max_test_samples=MAX_TEST_SAMPLES\n",
        "        )\n",
        "        eval_time = time.time() - eval_start\n",
        "    else:\n",
        "        # Use previous metrics to avoid breaking the history\n",
        "        hit_rate = training_history['hit_rate'][-1] if training_history['hit_rate'] else 0.0\n",
        "        ndcg_score = training_history['ndcg'][-1] if training_history['ndcg'] else 0.0\n",
        "        eval_time = 0\n",
        "        print(f\"  Skipping evaluation (evaluate every {EVAL_EVERY_N_EPOCHS} epochs)\")\n",
        "    \n",
        "    # Save best model based on HR\n",
        "    if hit_rate > best_hr + MIN_DELTA:\n",
        "        best_hr = hit_rate\n",
        "        best_ndcg = ndcg_score\n",
        "        best_epoch = epoch\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        print(f\"  ✓ New best model! (HR@{TOP_K}: {best_hr:.4f})\")\n",
        "        print(f\"  ✓ Model saved to {model_path}\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "    \n",
        "    # Track metrics\n",
        "    training_history['epoch'].append(epoch + 1)\n",
        "    training_history['train_loss'].append(train_loss)\n",
        "    training_history['hit_rate'].append(hit_rate)\n",
        "    training_history['ndcg'].append(ndcg_score)\n",
        "    \n",
        "    print(f\"  Time: {time.strftime('%H:%M:%S', time.gmtime(elapsed_time))}\")\n",
        "    print(f\"  Loss: {train_loss:.4f}\")\n",
        "    print(f\"  HR@{TOP_K}: {hit_rate:.4f}\")\n",
        "    print(f\"  NDCG@{TOP_K}: {ndcg_score:.4f}\")\n",
        "    \n",
        "    # Early stopping\n",
        "    if patience_counter >= EARLY_STOPPING_PATIENCE:\n",
        "        print(f\"\\n  Early stopping triggered (no improvement for {EARLY_STOPPING_PATIENCE} epochs)\")\n",
        "        break\n",
        "    \n",
        "    print(\"-\" * 70)\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"Training Complete!\")\n",
        "print(f\"Best model at epoch {best_epoch+1} with HR@{TOP_K}: {best_hr:.4f}, NDCG@{TOP_K}: {best_ndcg:.4f}\")\n",
        "print(f\"Model saved to: {model_path}\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization of training metrics\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "epochs = training_history['epoch']\n",
        "\n",
        "# Plot 1: Hit Rate\n",
        "axes[0].plot(epochs, training_history['hit_rate'], 'g-o', label=f'HR@{TOP_K}', linewidth=2, markersize=6)\n",
        "axes[0].axvline(x=best_epoch + 1, color='r', linestyle='--', alpha=0.7, label=f'Best Epoch ({best_epoch + 1})')\n",
        "axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0].set_ylabel('Hit Rate', fontsize=12)\n",
        "axes[0].set_title(f'Hit Rate@{TOP_K} Over Epochs', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].legend()\n",
        "axes[0].set_xticks(epochs[::5] if len(epochs) > 10 else epochs)\n",
        "\n",
        "# Plot 2: NDCG\n",
        "axes[1].plot(epochs, training_history['ndcg'], 'm-o', label=f'NDCG@{TOP_K}', linewidth=2, markersize=6)\n",
        "axes[1].axvline(x=best_epoch + 1, color='r', linestyle='--', alpha=0.7, label=f'Best Epoch ({best_epoch + 1})')\n",
        "axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1].set_ylabel('NDCG', fontsize=12)\n",
        "axes[1].set_title(f'NDCG@{TOP_K} Over Epochs', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "axes[1].legend()\n",
        "axes[1].set_xticks(epochs[::5] if len(epochs) > 10 else epochs)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print final metrics\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Final Training Metrics\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Best HR@{TOP_K}: {best_hr:.4f} (Epoch {best_epoch + 1})\")\n",
        "print(f\"Best NDCG@{TOP_K}: {best_ndcg:.4f} (Epoch {best_epoch + 1})\")\n",
        "if training_history['hit_rate']:\n",
        "    print(f\"Final HR@{TOP_K}: {training_history['hit_rate'][-1]:.4f}\")\n",
        "    print(f\"Final NDCG@{TOP_K}: {training_history['ndcg'][-1]:.4f}\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== COMPREHENSIVE VISUALIZATIONS ====================\n",
        "\n",
        "# 1. Training Metrics Overview\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "epochs = training_history['epoch']\n",
        "\n",
        "# Plot 1: Training Loss\n",
        "axes[0, 0].plot(epochs, training_history['train_loss'], 'b-o', label='Train Loss', linewidth=2, markersize=4, alpha=0.7)\n",
        "axes[0, 0].axvline(x=best_epoch + 1, color='r', linestyle='--', alpha=0.7, label=f'Best Epoch ({best_epoch + 1})')\n",
        "axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0, 0].set_ylabel('Loss', fontsize=12)\n",
        "axes[0, 0].set_title('Training Loss Over Epochs', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].set_xticks(epochs[::5] if len(epochs) > 10 else epochs)\n",
        "\n",
        "# Plot 2: Hit Rate\n",
        "axes[0, 1].plot(epochs, training_history['hit_rate'], 'g-o', label=f'HR@{TOP_K}', linewidth=2, markersize=4)\n",
        "axes[0, 1].axvline(x=best_epoch + 1, color='r', linestyle='--', alpha=0.7, label=f'Best Epoch ({best_epoch + 1})')\n",
        "axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0, 1].set_ylabel('Hit Rate', fontsize=12)\n",
        "axes[0, 1].set_title(f'Hit Rate@{TOP_K} Over Epochs', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].set_xticks(epochs[::5] if len(epochs) > 10 else epochs)\n",
        "if training_history['hit_rate']:\n",
        "    axes[0, 1].set_ylim([0, max(1.0, max(training_history['hit_rate']) * 1.1)])\n",
        "\n",
        "# Plot 3: NDCG\n",
        "axes[1, 0].plot(epochs, training_history['ndcg'], 'm-o', label=f'NDCG@{TOP_K}', linewidth=2, markersize=4)\n",
        "axes[1, 0].axvline(x=best_epoch + 1, color='r', linestyle='--', alpha=0.7, label=f'Best Epoch ({best_epoch + 1})')\n",
        "axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1, 0].set_ylabel('NDCG', fontsize=12)\n",
        "axes[1, 0].set_title(f'NDCG@{TOP_K} Over Epochs', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].set_xticks(epochs[::5] if len(epochs) > 10 else epochs)\n",
        "if training_history['ndcg']:\n",
        "    axes[1, 0].set_ylim([0, max(1.0, max(training_history['ndcg']) * 1.1)])\n",
        "\n",
        "# Plot 4: HR vs NDCG Comparison\n",
        "axes[1, 1].plot(epochs, training_history['hit_rate'], 'g-o', label=f'HR@{TOP_K}', linewidth=2, markersize=4)\n",
        "axes[1, 1].plot(epochs, training_history['ndcg'], 'm-s', label=f'NDCG@{TOP_K}', linewidth=2, markersize=4)\n",
        "axes[1, 1].axvline(x=best_epoch + 1, color='r', linestyle='--', alpha=0.7, label=f'Best Epoch ({best_epoch + 1})')\n",
        "axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1, 1].set_ylabel('Score', fontsize=12)\n",
        "axes[1, 1].set_title('HR vs NDCG Comparison', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].set_xticks(epochs[::5] if len(epochs) > 10 else epochs)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Get detailed metrics for best model\n",
        "print(\"\\nGenerating detailed analysis for best model...\")\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "hr_final, ndcg_final, details = evaluate_ranking_metrics(\n",
        "    model, train_mat, test_mat, num_users, num_items, top_k=TOP_K, device=device, return_details=True\n",
        ")\n",
        "\n",
        "# 3. User-Level Performance Analysis\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "user_hr = details['user_hr']\n",
        "user_ndcg = details['user_ndcg']\n",
        "user_test_counts = details['user_test_counts']\n",
        "\n",
        "# Plot 1: HR Distribution\n",
        "axes[0, 0].hist(user_hr, bins=50, edgecolor='black', alpha=0.7, color='green')\n",
        "axes[0, 0].axvline(x=np.mean(user_hr), color='r', linestyle='--', linewidth=2, \n",
        "                  label=f'Mean: {np.mean(user_hr):.4f}')\n",
        "axes[0, 0].set_xlabel('Hit Rate', fontsize=12)\n",
        "axes[0, 0].set_ylabel('Number of Users', fontsize=12)\n",
        "axes[0, 0].set_title(f'User-Level HR@{TOP_K} Distribution', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# Plot 2: NDCG Distribution\n",
        "axes[0, 1].hist(user_ndcg, bins=50, edgecolor='black', alpha=0.7, color='magenta')\n",
        "axes[0, 1].axvline(x=np.mean(user_ndcg), color='r', linestyle='--', linewidth=2, \n",
        "                 label=f'Mean: {np.mean(user_ndcg):.4f}')\n",
        "axes[0, 1].set_xlabel('NDCG', fontsize=12)\n",
        "axes[0, 1].set_ylabel('Number of Users', fontsize=12)\n",
        "axes[0, 1].set_title(f'User-Level NDCG@{TOP_K} Distribution', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "axes[0, 1].legend()\n",
        "\n",
        "# Plot 3: HR vs Test Item Count\n",
        "axes[1, 0].scatter(user_test_counts, user_hr, alpha=0.3, s=10)\n",
        "axes[1, 0].set_xlabel('Number of Test Items per User', fontsize=12)\n",
        "axes[1, 0].set_ylabel(f'HR@{TOP_K}', fontsize=12)\n",
        "axes[1, 0].set_title('HR vs Test Item Count', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "# Add trend line\n",
        "if len(user_test_counts) > 1:\n",
        "    z = np.polyfit(user_test_counts, user_hr, 1)\n",
        "    p = np.poly1d(z)\n",
        "    axes[1, 0].plot(sorted(user_test_counts), p(sorted(user_test_counts)), \"r--\", alpha=0.8, linewidth=2)\n",
        "\n",
        "# Plot 4: NDCG vs Test Item Count\n",
        "axes[1, 1].scatter(user_test_counts, user_ndcg, alpha=0.3, s=10, color='magenta')\n",
        "axes[1, 1].set_xlabel('Number of Test Items per User', fontsize=12)\n",
        "axes[1, 1].set_ylabel(f'NDCG@{TOP_K}', fontsize=12)\n",
        "axes[1, 1].set_title('NDCG vs Test Item Count', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "# Add trend line\n",
        "if len(user_test_counts) > 1:\n",
        "    z = np.polyfit(user_test_counts, user_ndcg, 1)\n",
        "    p = np.poly1d(z)\n",
        "    axes[1, 1].plot(sorted(user_test_counts), p(sorted(user_test_counts)), \"r--\", alpha=0.8, linewidth=2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Performance Across Different K Values\n",
        "print(\"\\nEvaluating performance across different K values...\")\n",
        "k_values = [5, 10, 20, 50]\n",
        "k_hr_scores = []\n",
        "k_ndcg_scores = []\n",
        "\n",
        "for k in k_values:\n",
        "    hr_k, ndcg_k = evaluate_ranking_metrics(\n",
        "        model, train_mat, test_mat, num_users, num_items, top_k=k, device=device\n",
        "    )\n",
        "    k_hr_scores.append(hr_k)\n",
        "    k_ndcg_scores.append(ndcg_k)\n",
        "    print(f\"  K={k:2d}: HR@{k}={hr_k:.4f}, NDCG@{k}={ndcg_k:.4f}\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Plot 1: HR@K for different K\n",
        "axes[0].plot(k_values, k_hr_scores, 'g-o', linewidth=2, markersize=8, label='Hit Rate')\n",
        "axes[0].set_xlabel('K (Top-K)', fontsize=12)\n",
        "axes[0].set_ylabel('Hit Rate', fontsize=12)\n",
        "axes[0].set_title('Hit Rate@K for Different K Values', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].legend()\n",
        "axes[0].set_xticks(k_values)\n",
        "for k, hr in zip(k_values, k_hr_scores):\n",
        "    axes[0].text(k, hr + 0.01, f'{hr:.3f}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "# Plot 2: NDCG@K for different K\n",
        "axes[1].plot(k_values, k_ndcg_scores, 'm-s', linewidth=2, markersize=8, label='NDCG')\n",
        "axes[1].set_xlabel('K (Top-K)', fontsize=12)\n",
        "axes[1].set_ylabel('NDCG', fontsize=12)\n",
        "axes[1].set_title('NDCG@K for Different K Values', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "axes[1].legend()\n",
        "axes[1].set_xticks(k_values)\n",
        "for k, ndcg in zip(k_values, k_ndcg_scores):\n",
        "    axes[1].text(k, ndcg + 0.01, f'{ndcg:.3f}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Performance Statistics\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Plot 1: HR Statistics Box Plot\n",
        "axes[0].boxplot([user_hr], vert=True, patch_artist=True,\n",
        "                boxprops=dict(facecolor='lightgreen', alpha=0.7),\n",
        "                medianprops=dict(color='red', linewidth=2))\n",
        "axes[0].set_ylabel('Hit Rate', fontsize=12)\n",
        "axes[0].set_title(f'HR@{TOP_K} Statistics (Box Plot)', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "axes[0].set_xticklabels(['HR'])\n",
        "stats_text = f'Mean: {np.mean(user_hr):.4f}\\nMedian: {np.median(user_hr):.4f}\\nStd: {np.std(user_hr):.4f}'\n",
        "axes[0].text(0.5, 0.95, stats_text, transform=axes[0].transAxes, \n",
        "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "# Plot 2: NDCG Statistics Box Plot\n",
        "axes[1].boxplot([user_ndcg], vert=True, patch_artist=True,\n",
        "               boxprops=dict(facecolor='plum', alpha=0.7),\n",
        "               medianprops=dict(color='red', linewidth=2))\n",
        "axes[1].set_ylabel('NDCG', fontsize=12)\n",
        "axes[1].set_title(f'NDCG@{TOP_K} Statistics (Box Plot)', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "axes[1].set_xticklabels(['NDCG'])\n",
        "stats_text = f'Mean: {np.mean(user_ndcg):.4f}\\nMedian: {np.median(user_ndcg):.4f}\\nStd: {np.std(user_ndcg):.4f}'\n",
        "axes[1].text(0.5, 0.95, stats_text, transform=axes[1].transAxes, \n",
        "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print final metrics\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Final Training Metrics\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Best HR@{TOP_K}: {best_hr:.4f} (Epoch {best_epoch + 1})\")\n",
        "print(f\"Best NDCG@{TOP_K}: {best_ndcg:.4f} (Epoch {best_epoch + 1})\")\n",
        "if training_history['hit_rate']:\n",
        "    print(f\"Final HR@{TOP_K}: {training_history['hit_rate'][-1]:.4f}\")\n",
        "    print(f\"Final NDCG@{TOP_K}: {training_history['ndcg'][-1]:.4f}\")\n",
        "print(f\"\\nUser-Level Statistics:\")\n",
        "print(f\"  HR@{TOP_K} - Mean: {np.mean(user_hr):.4f}, Median: {np.median(user_hr):.4f}, Std: {np.std(user_hr):.4f}\")\n",
        "print(f\"  NDCG@{TOP_K} - Mean: {np.mean(user_ndcg):.4f}, Median: {np.median(user_ndcg):.4f}, Std: {np.std(user_ndcg):.4f}\")\n",
        "print(\"=\" * 70)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
